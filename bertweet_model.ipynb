{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't run these, takes 8min (already saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet = AutoModel.from_pretrained('vinai/bertweet-large')\n",
    "tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-large', use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = 'saved'\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "bertweet.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bertweet base model\n",
    "save_directory = 'saved'\n",
    "bertweet = AutoModel.from_pretrained(save_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 31414, 232, 6, 42, 16, 127, 78, 86, 634, 12975, 21210, 328, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example string input to tokenizer\n",
    "line = \"Hello world, this is my first time using Bertweet!\"\n",
    "res = tokenizer(line)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0,  713,   16,  127,   78, 3645,    4,    2,    1,    1,    1,    1,\n",
       "            1,    1,    1],\n",
       "        [   0, 2409,   42,   16,  127,  200, 3645,    6,   38, 1034,   47, 1346,\n",
       "           24,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating batch for input into Bertweet\n",
    "X_train = ['This is my first sentence.', 'And this is my second sentence, I hope you understand it.']\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0453, -0.0353,  0.1269,  ...,  0.1318,  0.1431, -0.0268],\n",
      "         [ 0.1216, -0.1689, -0.8237,  ...,  0.3062, -0.3307,  0.3082],\n",
      "         [ 0.0916,  0.1439, -0.9215,  ...,  0.3699, -0.0623,  0.2387],\n",
      "         ...,\n",
      "         [-0.0136, -0.0934, -0.3526,  ...,  0.0756,  0.0351,  0.0351],\n",
      "         [-0.0136, -0.0934, -0.3526,  ...,  0.0756,  0.0351,  0.0351],\n",
      "         [-0.0136, -0.0934, -0.3526,  ...,  0.0756,  0.0351,  0.0351]],\n",
      "\n",
      "        [[-0.2916, -0.2605,  0.1840,  ...,  0.2022, -0.0896,  0.2360],\n",
      "         [ 0.0496,  0.3750, -0.7756,  ..., -0.0128,  0.2076,  0.1194],\n",
      "         [ 0.0489, -0.4376, -1.0619,  ...,  0.2605, -0.5458,  0.1574],\n",
      "         ...,\n",
      "         [-0.0306, -0.0894, -0.0339,  ..., -0.1659,  0.0283, -0.0898],\n",
      "         [ 0.0696,  0.0282,  0.0196,  ..., -0.0197,  0.2267, -0.0093],\n",
      "         [ 0.0338, -0.0204, -0.0525,  ..., -0.0569,  0.1598, -0.0067]]])\n",
      "torch.Size([2, 15, 1024])\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "with torch.no_grad():\n",
    "    outputs = bertweet(**batch)\n",
    "print(outputs.last_hidden_state)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 31414,   232,     6,    42,    16,   127,    78,    86,   634,\n",
      "         12975, 21210,   328,     2]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0285,  0.0044, -0.0314,  ...,  0.0243,  0.0553,  0.0443],\n",
       "         [-0.3286,  0.6190, -1.5636,  ..., -0.1887, -0.4045,  0.0190],\n",
       "         [ 0.0090,  0.2959, -0.4406,  ...,  0.4447, -0.1542,  0.1028],\n",
       "         ...,\n",
       "         [-0.1125, -0.3202, -0.2327,  ...,  0.1368,  0.3177,  0.0216],\n",
       "         [-0.4010,  0.1004, -0.4539,  ...,  0.0684, -0.1501, -0.0831],\n",
       "         [-0.0237, -0.0087, -0.0484,  ...,  0.0073,  0.0453,  0.0352]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2569,  0.4870, -0.4550,  ...,  0.3592, -0.4953, -0.7143]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative way to create input to bertweet\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(input_ids)\n",
    "bertweet(input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
